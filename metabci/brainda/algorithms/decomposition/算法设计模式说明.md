# 算法设计模式说明

## 概述

本文档总结了 `metabci/brainda/algorithms/decomposition` 文件夹中所有算法的共同设计模式和架构。

## 核心设计模式

### 三层架构：`_kernel` + `_feature` + 类封装

```
_kernel() 函数  →  训练阶段：学习空间滤波器（特征分解）
    ↓
_feature() 函数  →  特征提取和表示：应用滤波器提取特征并得到最终表示
    ↓
类封装 (fit/transform/predict)  →  完整的分类器接口
```

### 算法列表

| 算法 | `_kernel` 函数 | `_feature` 函数 | FilterBank版本 |
|------|---------------|----------------|----------------|
| **CSP** | `csp_kernel()` | `csp_feature()` | `FBCSP` |
| **DSP** | `xiang_dsp_kernel()` | `xiang_dsp_feature()` | `FBDSP` |
| **TDCA** | `xiang_dsp_kernel()` | `tdca_feature()` | `FBTDCA` |
| **CCA系列** | `_scca_kernel()` | `_scca_feature()` / `_itcca_feature()` / `_ecca_feature()` | `FBItCCA` / `FBECCA` |
| **TRCA** | `_trca_kernel()` | `_trca_feature()` | `FBTRCA` |
| **MsetCCA** | `_msetcca_kernel1/2()` | `_msetcca_feature2()` | `FBMsetCCA` |
| **SSCOR** | `sscor_kernel()` | `sscor_feature()` | `FBSSCOR` |

## 统一的类接口

所有算法类都提供统一的接口：

```python
class Algorithm(BaseEstimator, TransformerMixin, ClassifierMixin):
    def fit(self, X, y, ...):
        """训练：学习空间滤波器和模板"""
        # 1. 数据预处理（去均值）
        # 2. 学习空间滤波器（通过广义特征值分解）
        # 3. 计算模板（训练数据的平均）
        return self
    
    def transform(self, X):
        """特征提取和表示：返回最终特征表示"""
        # 1. 数据预处理
        # 2. 应用空间滤波器提取特征并得到最终表示
        return features  # (n_trials, n_classes) 或 (n_trials, n_components)
    
    def predict(self, X):
        """分类：基于特征表示进行预测"""
        feat = self.transform(X)
        return self.classes_[np.argmax(feat, axis=-1)]
```

## 特征处理的三个阶段

### 阶段1：特征分解（Feature Decomposition）

通过广义特征值分解学习空间滤波器：

```python
# 构建类间和类内散度矩阵
Sb = between_class_scatter_matrix(X, y)  # 类间散度
Sw = within_class_scatter_matrix(X, y)   # 类内散度

# 求解广义特征值问题: Sb @ W = λ @ Sw @ W
D, W = eigh(Sb, Sw)
```

**输出**：空间滤波器 W `(n_channels, n_components)`

### 阶段2：特征提取（Feature Extraction）

应用空间滤波器得到滤波后的信号：

```python
features = W[:, :n_components].T @ X
```

**输出**：滤波后的信号 `(n_components, n_samples)` - **这才是真正的"特征"**

### 阶段3：特征表示（Feature Representation）

对特征进行处理，得到用于分类的最终表示。有两种主要方式：

#### 方式A：模板匹配（相关系数）

**使用算法**：CCA系列、TRCA、TDCA、DSP、MsetCCA等

```python
# 1. 特征提取
a = W.T @ X  # (n_components, n_samples)

# 2. 与模板计算相关系数
rho = pearsonr(a.flatten(), template.flatten())[0]
```

**输出**：相关系数 `(n_trials, n_classes)`，范围 `[-1, 1]`  
**分类**：直接 `argmax`，无需额外分类器

#### 方式B：方差表示（CSP风格）

**使用算法**：CSP、MultiCSP等

```python
# 1. 特征提取
features = W.T @ X  # (n_components, n_samples)

# 2. 计算方差、归一化、对数变换
var = np.mean(np.square(features), axis=-1)
var_norm = var / np.sum(var)
log_var = np.log(var_norm)
```

**输出**：对数方差 `(n_trials, n_components)`，范围 `(-\infty, 0]`  
**分类**：需要额外分类器（SVM等）

## 两种表示方式对比

| 特性 | 相关系数表示 | 方差表示 |
|------|------------|---------|
| **使用算法** | CCA、TRCA、TDCA、DSP | CSP、MultiCSP |
| **输出形状** | `(n_trials, n_classes)` | `(n_trials, n_components)` |
| **数值范围** | `[-1, 1]` | `(-\infty, 0]` |
| **分类方式** | 直接`argmax` | 需要分类器 |
| **对幅度敏感** | ❌ 不敏感 | ✅ 敏感 |
| **适用场景** | SSVEP、P300等有模板的任务 | 运动想象等能量差异任务 |

## 空间滤波器的学习方式

### 广义特征值分解

所有算法都通过求解广义特征值问题来学习空间滤波器：

```python
Sb @ W = λ @ Sw @ W
```

**核心思想**：
- **类间散度 Sb**：衡量不同类别之间的差异（越大越好）
- **类内散度 Sw**：衡量同一类别内部的差异（越小越好）
- **目标**：找到投影矩阵 W，使得 `W.T @ Sb @ W` 最大，`W.T @ Sw @ W` 最小

### 不同算法的散度矩阵定义

| 算法 | 类间散度 Sb | 类内散度 Sw | 目标 |
|------|------------|------------|------|
| **CSP** | 类别1的协方差 | 两个类别的协方差之和 | 最大化类别1方差，最小化类别2方差 |
| **DSP** | 类别均值差异的协方差 | 类内协方差之和 | 最大化类间差异，最小化类内差异 |
| **TRCA** | Trial间协方差 | Trial内协方差 | 最大化trial间一致性 |
| **CCA** | 信号与参考信号的协方差 | 信号的自协方差 | 最大化与参考信号的相关性 |

**为什么不同算法有不同的定义？**

- **问题目标不同**：分类问题（CSP/DSP）vs 成分提取（TRCA）vs 相关性分析（CCA）
- **数据特点不同**：二分类 vs 多分类 vs 有参考信号
- **优化目标不同**：不同的数学优化目标

## FilterBank 模式

许多算法都有 FilterBank 版本（FB前缀），用于多频带特征融合：

```python
class FBAlgorithm(FilterBankSSVEP, ClassifierMixin):
    def fit(self, X, y, ...):
        """对每个频带分别训练"""
        for filter, algo in zip(self.filterbank, self.algorithms_):
            X_filtered = filter @ X
            algo.fit(X_filtered, y, ...)
    
    def transform(self, X):
        """对每个频带提取特征并融合"""
        features_list = []
        for filter, algo in zip(self.filterbank, self.algorithms_):
            features = algo.transform(filter @ X)
            features_list.append(features)
        # 融合（平均或加权平均）
        return np.mean(features_list, axis=0)
```

**优势**：多频带信息融合，提高鲁棒性和准确率

## 算法分类

### 按特征表示方式分类

- **模板匹配类（相关系数）**：CCA系列、TRCA、TDCA、DSP、MsetCCA
- **方差表示类**：CSP、MultiCSP

### 按是否使用参考信号分类

- **使用参考信号**：CCA系列（需要正弦/余弦模板）、TRCA（使用trial间一致性）
- **不使用参考信号**：CSP、DSP、TDCA（仅基于类别标签）

## 代码示例

### CSP（方差表示）

```python
from metabci.brainda.algorithms.decomposition import CSP
from sklearn.svm import SVC

csp = CSP(n_components=4)
csp.fit(X_train, y_train)
features = csp.transform(X_test)  # (n_trials, 4)

clf = SVC()
clf.fit(csp.transform(X_train), y_train)
labels = clf.predict(features)
```

### TRCA（模板匹配）

```python
from metabci.brainda.algorithms.decomposition import TRCA

trca = TRCA(n_components=1)
trca.fit(X_train, y_train)
features = trca.transform(X_test)  # (n_trials, n_classes)
labels = trca.predict(X_test)  # 直接分类，无需额外分类器
```

## 总结

### 核心共同点

1. ✅ **统一的三层架构**：`_kernel` + `_feature` + 类封装
2. ✅ **空间滤波器学习**：通过广义特征值分解
3. ✅ **标准接口**：fit/transform/predict
4. ✅ **特征表示**：模板匹配（相关系数）或方差表示
5. ✅ **FilterBank支持**：多频带特征融合
6. ✅ **都需要校准（训练）**：所有算法必须通过 `fit()` 方法使用带标签的训练数据进行校准

### 主要差异

1. **散度矩阵定义**：不同算法有不同的类间/类内散度定义
2. **特征表示**：相关系数 vs 方差
3. **参考信号**：部分算法使用参考信号（CCA系列），部分不使用（CSP）
4. **多类别支持**：CSP主要支持2类，其他算法支持多类

---

**文档版本**：1.0  
**最后更新**：2025年  
**作者**：MetaBCI 团队
